{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WESAD 数据集分析与模型训练\n",
    "\n",
    "#### 加载数据\n",
    "我们首先加载WESAD数据集中的特定受试者的数据。每个受试者的数据存储在一个`.pkl`文件中，包含了信号数据、标签和受试者信息。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['signal', 'label', 'subject'])\n",
      "dict_keys(['chest', 'wrist'])\n",
      "dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
      "(4255300, 1)\n",
      "S2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_wesad_data(participant_id, data_path='WESAD'):\n",
    "    file_path = os.path.join(data_path, f'S{participant_id}', f'S{participant_id}.pkl')\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "    return data\n",
    "\n",
    "# 加载特定受试者的数据\n",
    "participant_id = 2  # 示例中加载第2个受试者的数据\n",
    "data = load_wesad_data(participant_id)\n",
    "\n",
    "# 查看数据结构\n",
    "print(data.keys())  # dict_keys(['signal', 'label', 'subject'])\n",
    "print(data['signal'].keys())  # dict_keys(['chest', 'wrist'])\n",
    "print(data['signal']['chest'].keys())  # dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
    "print(data['signal']['chest']['ECG'].shape)  # 查看具体数据的形状\n",
    "# 查看label的标签\n",
    "print(data['subject'])  # S2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据结构分析\n",
    "\n",
    "- **信号数据（signal）**：包括来自`chest`和`wrist`传感器的数据。\n",
    "  - **胸部传感器（chest）**：\n",
    "    - **ACC**：加速度计数据，用于测量运动和振动。\n",
    "    - **ECG**：心电图数据，用于分析心脏活动。\n",
    "    - **EMG**：肌电图数据，用于测量肌肉活动。\n",
    "    - **EDA**：皮肤电活动数据，用于测量皮肤电导率变化。\n",
    "    - **Temp**：体温数据，用于测量皮肤表面温度。\n",
    "    - **Resp**：呼吸数据，用于测量呼吸频率和深度。\n",
    "- **标签数据（label）**：情绪和压力状态的标签。\n",
    "- **受试者信息（subject）**：包含受试者的基本信息。\n",
    "\n",
    "数据的维度：\n",
    "- 数据包含4255300个样本，每个样本有6个特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签的唯一值: [0 1 2 3 4 6 7]\n",
      "标签的最大值: 7\n",
      "标签的最小值: 0\n",
      "(4255300, 6)\n",
      "(4255300,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    ecg_data = data['signal']['chest']['ECG']\n",
    "    eda_data = data['signal']['chest']['EDA'].reshape(-1, 1)\n",
    "    temp_data = data['signal']['chest']['Temp'].reshape(-1, 1)\n",
    "    acc_data = data['signal']['chest']['ACC']\n",
    "    \n",
    "    # 确保所有数据的长度相同\n",
    "    min_length = min(len(ecg_data), len(eda_data), len(temp_data), len(acc_data))\n",
    "    ecg_data = ecg_data[:min_length]\n",
    "    eda_data = eda_data[:min_length]\n",
    "    temp_data = temp_data[:min_length]\n",
    "    acc_data = acc_data[:min_length]\n",
    "\n",
    "    combined_data = np.hstack((ecg_data, eda_data, temp_data, acc_data))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    combined_data = scaler.fit_transform(combined_data)\n",
    "    \n",
    "    labels = data['label'][:min_length]\n",
    "    \n",
    "    # 输出标签的唯一值和范围\n",
    "    print(f\"标签的唯一值: {np.unique(labels)}\")\n",
    "    print(f\"标签的最大值: {np.max(labels)}\")\n",
    "    print(f\"标签的最小值: {np.min(labels)}\")\n",
    "    \n",
    "    return combined_data, labels\n",
    "\n",
    "preprocessed_data, labels = preprocess_data(data)\n",
    "print(preprocessed_data.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签的唯一值: [0 1 2 3 4 6 7]\n",
      "标签的最大值: 7\n",
      "标签的最小值: 0\n",
      "维度 1 (ECG) 的标签值: [ 0.13117504  0.12404464  0.09938534 ... -0.04322267 -0.00697647\n",
      "  0.01857413]\n",
      "维度 2 (EDA) 的标签值: [ 3.00556138  3.01911462  2.99970884 ... -0.94305162 -0.93873923\n",
      " -0.93904726]\n",
      "维度 3 (Temp) 的标签值: [-0.59005113 -0.58321442 -0.57642536 ...  0.45472658  0.47428385\n",
      "  0.45241591]\n",
      "维度 4 (ACC_X) 的标签值: [1.1508615  0.98183069 0.88132631 ... 0.67346382 0.68031688 0.66432756]\n",
      "维度 5 (ACC_Y) 的标签值: [-1.38394068 -1.37770742 -1.34654205 ...  0.14629919  0.15253245\n",
      "  0.1743484 ]\n",
      "维度 6 (ACC_Z) 的标签值: [-0.45070835 -0.43671941 -0.38809102 ...  0.39462741  0.39995645\n",
      "  0.40128876]\n",
      "(4255300, 6)\n",
      "(4255300,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    ecg_data = data['signal']['chest']['ECG']\n",
    "    eda_data = data['signal']['chest']['EDA'].reshape(-1, 1)\n",
    "    temp_data = data['signal']['chest']['Temp'].reshape(-1, 1)\n",
    "    acc_data = data['signal']['chest']['ACC']\n",
    "    \n",
    "    # 确保所有数据的长度相同\n",
    "    min_length = min(len(ecg_data), len(eda_data), len(temp_data), len(acc_data))\n",
    "    ecg_data = ecg_data[:min_length]\n",
    "    eda_data = eda_data[:min_length]\n",
    "    temp_data = temp_data[:min_length]\n",
    "    acc_data = acc_data[:min_length]\n",
    "\n",
    "    combined_data = np.hstack((ecg_data, eda_data, temp_data, acc_data))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    combined_data = scaler.fit_transform(combined_data)\n",
    "    \n",
    "    labels = data['label'][:min_length]\n",
    "    \n",
    "    # 输出标签的唯一值和范围\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"标签的唯一值: {unique_labels}\")\n",
    "    print(f\"标签的最大值: {np.max(labels)}\")\n",
    "    print(f\"标签的最小值: {np.min(labels)}\")\n",
    "    \n",
    "    # 输出每一个维度的标签以及对应的维度\n",
    "    dimension_labels = ['ECG', 'EDA', 'Temp', 'ACC_X', 'ACC_Y', 'ACC_Z']\n",
    "    for i, label in enumerate(dimension_labels):\n",
    "        print(f\"维度 {i+1} ({label}) 的标签值: {combined_data[:, i]}\")\n",
    "    \n",
    "    return combined_data, labels\n",
    "\n",
    "preprocessed_data, labels = preprocess_data(data)\n",
    "print(preprocessed_data.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独实现\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 将数据转换为PyTorch张量\n",
    "X_tensor = torch.tensor(preprocessed_data, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_size = int(0.8 * len(X_tensor))\n",
    "test_size = len(X_tensor) - train_size\n",
    "X_train, X_test = torch.utils.data.random_split(TensorDataset(X_tensor, y_tensor), [train_size, test_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(X_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(X_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义CNN模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * (input_size // 2), 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 64 * (x.shape[2]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "input_size = preprocessed_data.shape[1]\n",
    "num_classes = len(np.unique(labels))\n",
    "model = SimpleCNN(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.unsqueeze(1)  # 添加通道维度\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 划分训练集和测试集\n",
    "\n",
    "我们将预处理后的数据集划分为训练集和测试集，其中20%的数据用于测试，80%的数据用于训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建和训练模型\n",
    "\n",
    "使用PyTorch构建和训练一个简单的卷积神经网络（CNN）模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集标签的唯一值: [0 1 2 3 4 6 7]\n",
      "测试集标签的唯一值: [0 1 2 3 4 6 7]\n",
      "类别数: 7\n",
      "输入张量的形状: torch.Size([32, 1, 6])\n",
      "标签张量的形状: torch.Size([32]), 标签: tensor([4, 0, 0, 4, 0, 4, 0, 3, 2, 4, 0, 1, 0, 4, 0, 0, 0, 0, 1, 4, 0, 4, 0, 1,\n",
      "        0, 4, 3, 1, 0, 0, 0, 0])\n",
      "模型输出的形状: torch.Size([32, 7]), 输出: tensor([[ 0.0706,  0.0507,  0.2244,  0.1398, -0.1710,  0.2390, -0.1726],\n",
      "        [ 0.1827, -0.0148,  0.2556,  0.1626, -0.0368,  0.1507, -0.0920],\n",
      "        [ 0.4400,  0.1939,  0.2683,  0.1646, -0.2736,  0.3212, -0.0038],\n",
      "        [ 0.1223,  0.0279,  0.2056,  0.1041, -0.0901,  0.1405, -0.0888],\n",
      "        [-0.0193,  0.0948,  0.2325,  0.1827, -0.2816,  0.2274, -0.1541],\n",
      "        [ 0.0451,  0.0693,  0.2068,  0.1399, -0.1906,  0.2479, -0.1803],\n",
      "        [ 0.2539,  0.0896,  0.3333,  0.1771, -0.1736,  0.2243, -0.1259],\n",
      "        [ 0.1679, -0.0799,  0.2240,  0.1677,  0.0016,  0.1273, -0.0868],\n",
      "        [ 0.1137, -0.0570,  0.1935,  0.1327,  0.0543,  0.0816, -0.0471],\n",
      "        [ 0.1080,  0.0640,  0.2073,  0.0865, -0.1021,  0.1646, -0.0938],\n",
      "        [ 0.1719, -0.0947,  0.2247,  0.1624,  0.0207,  0.1292, -0.0813],\n",
      "        [ 0.0722,  0.0768,  0.1458,  0.2298, -0.2236,  0.0505, -0.1232],\n",
      "        [ 0.1617,  0.0076,  0.2219,  0.1459, -0.0590,  0.1636, -0.0181],\n",
      "        [ 0.1954,  0.0874,  0.2373,  0.0531, -0.0922,  0.1300, -0.0523],\n",
      "        [ 0.4139,  0.1377,  0.4316,  0.0412, -0.0265,  0.0999,  0.0617],\n",
      "        [ 0.0675,  0.0968,  0.2037,  0.1790, -0.1953,  0.1858, -0.1830],\n",
      "        [ 0.0169, -0.0073,  0.1649,  0.1869,  0.0374,  0.1082,  0.0094],\n",
      "        [ 0.1395, -0.0423,  0.1911,  0.1300,  0.0531,  0.0818, -0.0205],\n",
      "        [ 0.1145,  0.0783,  0.1575,  0.2077, -0.1960,  0.0620, -0.1073],\n",
      "        [ 0.0145,  0.0432,  0.2078,  0.1272, -0.0935,  0.1422, -0.0401],\n",
      "        [ 0.0434,  0.0151,  0.1887,  0.2389, -0.0218,  0.1065,  0.0194],\n",
      "        [ 0.0803,  0.0663,  0.2143,  0.1387, -0.1790,  0.2499, -0.1811],\n",
      "        [ 0.1286, -0.0473,  0.1846,  0.1280,  0.0512,  0.0779, -0.0309],\n",
      "        [ 0.0946,  0.0792,  0.1454,  0.2069, -0.1854,  0.0636, -0.1189],\n",
      "        [ 0.4382,  0.1725,  0.2699,  0.1632, -0.2365,  0.2936, -0.0021],\n",
      "        [ 0.0342,  0.0650,  0.2076,  0.1339, -0.1850,  0.2471, -0.1749],\n",
      "        [ 0.2007, -0.0886,  0.2234,  0.1539,  0.0094,  0.1230, -0.0830],\n",
      "        [ 0.1804,  0.0680,  0.1743,  0.1718, -0.1815,  0.0643, -0.0823],\n",
      "        [ 0.1601, -0.0394,  0.1874,  0.1191,  0.0137,  0.0888, -0.0371],\n",
      "        [ 0.1253, -0.0347,  0.1957,  0.1391,  0.0128,  0.1027, -0.0705],\n",
      "        [ 0.1482,  0.1190,  0.2677,  0.1592, -0.1649,  0.1791, -0.1244],\n",
      "        [ 0.0635, -0.0530,  0.2069,  0.1553,  0.0278,  0.1135, -0.0434]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "损失: 1.9465199708938599\n",
      "输入张量的形状: torch.Size([32, 1, 6])\n",
      "标签张量的形状: torch.Size([32]), 标签: tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 7, 0, 0, 0])\n",
      "模型输出的形状: torch.Size([32, 7]), 输出: tensor([[ 0.2219,  0.0460,  0.2347,  0.1214, -0.0819,  0.1982, -0.1802],\n",
      "        [ 0.6602,  0.1606,  0.2169,  0.0699, -0.3504,  0.3047, -0.0974],\n",
      "        [ 0.3416, -0.0448,  0.2612,  0.1997, -0.0282,  0.2117, -0.1939],\n",
      "        [ 0.1198,  0.0892,  0.1403,  0.1319, -0.1464,  0.1561, -0.2215],\n",
      "        [ 0.3653,  0.0029,  0.3459,  0.2352,  0.0386,  0.3584, -0.0354],\n",
      "        [ 0.1778,  0.1698,  0.0811,  0.1803, -0.1917,  0.0321, -0.1703],\n",
      "        [ 0.6851,  0.2541,  0.2586,  0.0344, -0.3704,  0.3345, -0.0753],\n",
      "        [ 0.1161, -0.1045,  0.1556,  0.1901,  0.0562,  0.0695, -0.0866],\n",
      "        [ 0.1553, -0.0823,  0.1482,  0.1418,  0.0726,  0.0800, -0.0865],\n",
      "        [ 0.1661,  0.0563,  0.1513,  0.0924, -0.1071,  0.2153, -0.2315],\n",
      "        [ 0.7670,  0.1843,  0.2220,  0.0795, -0.5417,  0.4103, -0.1734],\n",
      "        [ 0.3004, -0.1028,  0.1789,  0.1543,  0.0212,  0.1291, -0.1325],\n",
      "        [ 0.1571,  0.0751,  0.1570,  0.1252, -0.1362,  0.1811, -0.2283],\n",
      "        [ 0.1997, -0.0572,  0.1888,  0.1263,  0.0593,  0.0728, -0.0660],\n",
      "        [ 0.0781,  0.0455,  0.1541,  0.1010, -0.1442,  0.1956, -0.1979],\n",
      "        [ 0.1903,  0.0988,  0.1659,  0.1354, -0.1569,  0.1743, -0.2454],\n",
      "        [ 0.2650,  0.1503,  0.1077,  0.1554, -0.1591,  0.0233, -0.1418],\n",
      "        [ 0.1539, -0.0394,  0.1416,  0.1178,  0.0566,  0.0578, -0.0615],\n",
      "        [ 0.1912,  0.0905,  0.1676,  0.1221, -0.1443,  0.1752, -0.2386],\n",
      "        [ 0.0953,  0.1413,  0.0617,  0.1458, -0.2135,  0.0715, -0.1871],\n",
      "        [ 0.1467,  0.0740,  0.1553,  0.1277, -0.1409,  0.1789, -0.2277],\n",
      "        [ 0.1067, -0.0536,  0.1413,  0.1409,  0.0495,  0.1007, -0.0776],\n",
      "        [ 0.4557,  0.1773,  0.1468,  0.0138, -0.3063,  0.1373, -0.1166],\n",
      "        [ 0.2277, -0.0393,  0.1717,  0.1215,  0.0567,  0.0664, -0.0356],\n",
      "        [ 0.2100, -0.1094,  0.1799,  0.1631,  0.0549,  0.0860, -0.1073],\n",
      "        [ 0.0999,  0.0812,  0.1625,  0.1364, -0.1761,  0.1842, -0.2162],\n",
      "        [ 0.2209, -0.0415,  0.1682,  0.1052,  0.0354,  0.0746, -0.0611],\n",
      "        [ 0.1692, -0.0424,  0.1756,  0.1258,  0.0429,  0.0751, -0.0890],\n",
      "        [ 0.1963, -0.1086,  0.1819,  0.1619,  0.0622,  0.0813, -0.1008],\n",
      "        [ 0.1890, -0.0811,  0.1583,  0.1430,  0.0666,  0.0794, -0.0963],\n",
      "        [ 0.1136, -0.0397,  0.1845,  0.1399,  0.0425,  0.0900, -0.0611],\n",
      "        [ 0.1799, -0.0610,  0.1605,  0.1278,  0.0509,  0.0768, -0.0834]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 7 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\code\\ML-DL-RL-Learning\\ML-Learning\\Other\\WESAD\\index.ipynb 单元格 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/code/ML-DL-RL-Learning/ML-Learning/Other/WESAD/index.ipynb#X14sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/code/ML-DL-RL-Learning/ML-Learning/Other/WESAD/index.ipynb#X14sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m模型输出的形状: \u001b[39m\u001b[39m{\u001b[39;00moutputs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, 输出: \u001b[39m\u001b[39m{\u001b[39;00moutputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/code/ML-DL-RL-Learning/ML-Learning/Other/WESAD/index.ipynb#X14sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/code/ML-DL-RL-Learning/ML-Learning/Other/WESAD/index.ipynb#X14sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m损失: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/code/ML-DL-RL-Learning/ML-Learning/Other/WESAD/index.ipynb#X14sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\py311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\py311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\py311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1180\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1181\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\py311\\Lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 7 is out of bounds."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 将数据转换为PyTorch张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 打印标签的唯一值，确保标签范围正确\n",
    "print(f\"训练集标签的唯一值: {np.unique(y_train_tensor.numpy())}\")\n",
    "print(f\"测试集标签的唯一值: {np.unique(y_test_tensor.numpy())}\")\n",
    "\n",
    "# 确定类别数\n",
    "num_classes = len(np.unique(y_train_tensor.numpy()))\n",
    "print(f\"类别数: {num_classes}\")\n",
    "\n",
    "# 定义CNN模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * ((X_train_tensor.shape[1] - 1) // 2), 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)  # 动态设置类别数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.unsqueeze(1)  # 添加通道维度\n",
    "        print(f\"输入张量的形状: {inputs.shape}\")\n",
    "        print(f\"标签张量的形状: {labels.shape}, 标签: {labels}\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        print(f\"模型输出的形状: {outputs.shape}, 输出: {outputs}\")\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(f\"损失: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.unsqueeze(1)  # 添加通道维度\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'测试集准确率: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
